# TitanIA: Enterprise AI Reasoning Platform

TitanIA is a full-stack AI platform designed to demonstrate advanced reasoning capabilities using **RAG (Retrieval-Augmented Generation)** and **Multi-Agent Systems**. It simulates an enterprise environment where documents are ingested, analyzed by a team of AI agents, and used to make data-driven decisions with a complete audit trail.

![TitanIA Dashboard](assets/dashboard-screenshot.png)

## ğŸš€ Features

*   **ğŸ“„ Document Ingestion Pipeline**: Upload PDF, TXT, or CSV files. The system chunks, embeds, and indexes them into a Vector Database (**ChromaDB**).
*   **ğŸ§  RAG Engine**: Advanced retrieval using Semantic Search and **Cross-Encoder Re-ranking** for high relevance.
*   **ğŸ¤– Multi-Agent System (LangGraph)**:
    *   **Research Agent**: Gathers facts from the knowledge base.
    *   **Risk Agent**: Analyzes potential risks and compliance issues.
    *   **Decision Agent**: Synthesizes information to provide a final recommendation.
    *   **Audit Agent**: Logs every step of the reasoning process for transparency.
*   **ğŸ–¥ï¸ Modern Frontend**: A clean, responsive dashboard built with **React** and **TailwindCSS**.
*   **ğŸ”Œ FastAPI Backend**: Robust Python API handling asynchronous tasks and agent orchestration.

## ğŸ› ï¸ Tech Stack

*   **Backend**: Python, FastAPI, LangChain, LangGraph, ChromaDB, Sentence-Transformers.
*   **Frontend**: React (Vite), TailwindCSS, Axios.
*   **AI/ML**: HuggingFace Embeddings (`all-MiniLM-L6-v2`), Cross-Encoders (`ms-marco-MiniLM-L-6-v2`).

## ğŸ“¦ Installation & Setup

### Prerequisites
*   Python 3.9+
*   Node.js 16+

### 1. Clone the Repository
```bash
git clone https://github.com/yourusername/TitanIA.git
cd TitanIA
```

### 2. Backend Setup
```bash
cd backend
# Create virtual environment (optional but recommended)
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run the server
uvicorn app.main:app --reload
```
The backend will start at `http://localhost:8000`.

### 3. Frontend Setup
```bash
cd frontend
# Install dependencies
npm install

# Run the development server
npm run dev
```
The frontend will start at `http://localhost:5173`.

## ğŸ® Usage

1.  Open the dashboard at `http://localhost:5173`.
2.  **Upload a Document**: Use the upload section to add a PDF or text file to the knowledge base.
3.  **Ask a Question**: Type a query in the "Ask TitanIA" box (e.g., *"What are the key risks in this document?"*).
4.  **View Results**: Watch as the agents process your request and display the Final Decision, Risk Analysis, and Audit Log.

## ğŸ“‚ Project Structure

```
TitanIA/
â”œâ”€â”€ backend/            # FastAPI Server & AI Logic
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ agents/     # LangGraph Agent Definitions
â”‚   â”‚   â”œâ”€â”€ rag/        # Vector Store & Retrieval Logic
â”‚   â”‚   â”œâ”€â”€ ingestion/  # Document Loaders & Chunking
â”‚   â”‚   â””â”€â”€ main.py     # API Entry Point
â”‚   â””â”€â”€ requirements.txt
â””â”€â”€ frontend/           # React Application
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ components/ # UI Components
    â”‚   â””â”€â”€ App.jsx     # Main Layout
    â””â”€â”€ package.json
```

## ï¿½ Deployment

### Live Demo
**Frontend**: Deployed on AWS S3 + CloudFront  
ğŸ”— [http://titania-frontend-v1.s3-website-us-east-1.amazonaws.com](http://titania-frontend-v1.s3-website-us-east-1.amazonaws.com)

### Infrastructure Requirements
This is a **production-grade AI system** with enterprise-level dependencies:
- **PyTorch** (888 MB) - Deep learning framework
- **CUDA Libraries** (2+ GB) - GPU acceleration support
- **LangChain + ChromaDB** - Vector database and RAG pipeline
- **Sentence Transformers** - Embedding models

**Recommended AWS Setup:**
- **Frontend**: S3 + CloudFront (âœ… Currently deployed)
- **Backend**: EC2 t3.medium or larger (2GB+ RAM, 20GB+ disk)
- **Alternative**: AWS Lambda with containerized inference (for cost optimization)

> **Note**: AWS Free Tier (t2.micro/t3.micro) has insufficient resources for the ML stack. For local development, all components run seamlessly on standard hardware.

For detailed deployment instructions, see [`aws_deployment_guide.md`](aws_deployment_guide.md).

## ï¿½ğŸ›¡ï¸ License

This project is open-source and available under the MIT License.
